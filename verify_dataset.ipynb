{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"processed_data/autoencoder/001_data.h5\"\n",
    "\n",
    "# Open the H5 file\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    # Print the keys (dataset names) in the file\n",
    "    print(\"Datasets in the file:\", list(f.keys()))\n",
    "    \n",
    "    # Iterate through each dataset\n",
    "    for key in f.keys():\n",
    "        dataset = f[key]\n",
    "        print(f\"\\nDataset: {key}\")\n",
    "        print(f\"Shape: {dataset.shape}\")\n",
    "        print(f\"Dtype: {dataset.dtype}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path, 'r') as f:\n",
    "    # Get the number of datasets and images to display\n",
    "    num_datasets = len(f.keys())\n",
    "    num_samples = 100  # Number of samples to show for each dataset\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(6*num_datasets, 6*num_samples))\n",
    "    fig.suptitle(\"Dataset Visualizations\", y=0.99)\n",
    "    \n",
    "    # Iterate through each dataset\n",
    "    for i, key in enumerate(f.keys()):\n",
    "        dataset = f[key]\n",
    "        data = dataset[:]\n",
    "        total_samples = len(data)\n",
    "        \n",
    "        # Show multiple samples for each dataset\n",
    "        for j in range(num_samples):\n",
    "            # Calculate index from the end of the dataset\n",
    "            idx = total_samples - num_samples + j\n",
    "            \n",
    "            # Create a subplot for each sample\n",
    "            plt.subplot(num_samples, num_datasets, i + j*num_datasets + 1)\n",
    "            \n",
    "            # Plot specific visualizations based on the dataset\n",
    "            if key == 'images':\n",
    "                plt.imshow((data[idx] + 1) * 127.5, cmap='gray')\n",
    "                plt.title(f\"Image {idx+1}\" if j == 0 else None)\n",
    "            elif key == 'semantic_maps':\n",
    "                im = plt.imshow(data[idx], cmap='gray')\n",
    "                plt.title(f\"Semantic Map {idx+1}\" if j == 0 else None)\n",
    "            elif key == 'edges':\n",
    "                plt.imshow(data[idx] * 255, cmap='gray')\n",
    "                plt.title(f\"Edge Map {idx+1}\" if j == 0 else None)\n",
    "            \n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
