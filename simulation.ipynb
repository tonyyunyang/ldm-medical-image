{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def simulate_conv_shape(input_shape, conv_layers):\n",
    "    \"\"\"\n",
    "    Simulates the output shape after passing through a series of Conv2D layers.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Input shape as (batch_size, channels, height, width)\n",
    "        conv_layers (list): List of dictionaries containing Conv2D parameters\n",
    "            Each dict should have: out_channels, kernel_size, stride, padding\n",
    "            \n",
    "    Returns:\n",
    "        list: Shape at each layer\n",
    "    \"\"\"\n",
    "    device = torch.device('cpu')\n",
    "    shapes = [input_shape]\n",
    "    current_shape = input_shape\n",
    "    \n",
    "    # Create a dummy tensor\n",
    "    x = torch.randn(current_shape, device=device)\n",
    "    \n",
    "    # Process each conv layer\n",
    "    for i, layer_params in enumerate(conv_layers):\n",
    "        # Create Conv2D layer\n",
    "        conv = nn.Conv2d(\n",
    "            in_channels=current_shape[1],\n",
    "            out_channels=layer_params['out_channels'],\n",
    "            kernel_size=layer_params['kernel_size'],\n",
    "            stride=layer_params.get('stride', 1),\n",
    "            padding=layer_params.get('padding', 0)\n",
    "        ).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        x = conv(x)\n",
    "        current_shape = tuple(x.shape)\n",
    "        shapes.append(current_shape)\n",
    "        \n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_shape = (1, 1, 256, 256)  # batch_size=1, channels=3, height=32, width=32\n",
    "conv_layers = [\n",
    "    {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'out_channels': 128, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'out_channels': 128, 'kernel_size': 4, 'stride': 2, 'padding': 1},\n",
    "    {'out_channels': 256, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'out_channels': 256, 'kernel_size': 4, 'stride': 2, 'padding': 1},\n",
    "    {'out_channels': 256, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'out_channels': 256, 'kernel_size': 4, 'stride': 2, 'padding': 1},\n",
    "    {'out_channels': 4, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "]\n",
    "\n",
    "shapes = simulate_conv_shape(input_shape, conv_layers)\n",
    "for i, shape in enumerate(shapes):\n",
    "    print(f\"Layer {i}: {shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
